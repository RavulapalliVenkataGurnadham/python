{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Obtaining dependency information for selenium from https://files.pythonhosted.org/packages/b4/f9/e9ac5e4c5d84b07c7d117d67b2c84be221bcb9e62ff31fd0a1bbc06099c0/selenium-4.19.0-py3-none-any.whl.metadata\n",
      "  Downloading selenium-4.19.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\venkatagurnadhamravu\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Obtaining dependency information for trio~=0.17 from https://files.pythonhosted.org/packages/17/c9/f86f89f14d52f9f2f652ce24cb2f60141a51d087db1563f3fba94ba07346/trio-0.25.0-py3-none-any.whl.metadata\n",
      "  Downloading trio-0.25.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Obtaining dependency information for trio-websocket~=0.9 from https://files.pythonhosted.org/packages/48/be/a9ae5f50cad5b6f85bd2574c2c923730098530096e170c1ce7452394d7aa/trio_websocket-0.11.1-py3-none-any.whl.metadata\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\venkatagurnadhamravu\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Collecting typing_extensions>=4.9.0 (from selenium)\n",
      "  Obtaining dependency information for typing_extensions>=4.9.0 from https://files.pythonhosted.org/packages/01/f3/936e209267d6ef7510322191003885de524fc48d1b43269810cd589ceaf5/typing_extensions-4.11.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for attrs>=23.2.0 from https://files.pythonhosted.org/packages/e0/44/827b2a91a5816512fcaf3cc4ebc465ccd5d598c45cefa6703fcf4a79018f/attrs-23.2.0-py3-none-any.whl.metadata\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\venkatagurnadhamravu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\venkatagurnadhamravu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for outcome from https://files.pythonhosted.org/packages/55/8b/5ab7257531a5d830fc8000c476e63c935488d74609b50f9384a643ec0a62/outcome-1.3.0.post0-py2.py3-none-any.whl.metadata\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for sniffio>=1.3.0 from https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl.metadata\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\venkatagurnadhamravu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Obtaining dependency information for wsproto>=0.14 from https://files.pythonhosted.org/packages/78/58/e860788190eba3bcce367f74d29c4675466ce8dddfba85f7827588416f01/wsproto-1.2.0-py3-none-any.whl.metadata\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\venkatagurnadhamravu\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\venkatagurnadhamravu\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Obtaining dependency information for h11<1,>=0.9.0 from https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl.metadata\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading selenium-4.19.0-py3-none-any.whl (10.5 MB)\n",
      "   ---------------------------------------- 0.0/10.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.5 MB 653.6 kB/s eta 0:00:17\n",
      "   ---------------------------------------- 0.1/10.5 MB 651.6 kB/s eta 0:00:16\n",
      "   ---------------------------------------- 0.1/10.5 MB 837.8 kB/s eta 0:00:13\n",
      "    --------------------------------------- 0.2/10.5 MB 926.0 kB/s eta 0:00:12\n",
      "    --------------------------------------- 0.2/10.5 MB 1.0 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.4/10.5 MB 1.1 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.4/10.5 MB 1.1 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.5/10.5 MB 1.3 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.6/10.5 MB 1.3 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.7/10.5 MB 1.5 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.7/10.5 MB 1.5 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.9/10.5 MB 1.6 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.9/10.5 MB 1.6 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.1/10.5 MB 1.6 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.2/10.5 MB 1.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.4/10.5 MB 1.7 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.5/10.5 MB 1.8 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.6/10.5 MB 1.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.7/10.5 MB 1.9 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.9/10.5 MB 1.9 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.0/10.5 MB 2.0 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.1/10.5 MB 1.9 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.3/10.5 MB 2.0 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.4/10.5 MB 2.1 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.6/10.5 MB 2.1 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.6/10.5 MB 2.1 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.8/10.5 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.9/10.5 MB 2.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.0/10.5 MB 2.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.1/10.5 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.4/10.5 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.4/10.5 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.7/10.5 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.8/10.5 MB 2.3 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.0/10.5 MB 2.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.1/10.5 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.3/10.5 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.5/10.5 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.7/10.5 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.9/10.5 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.0/10.5 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.2/10.5 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.4/10.5 MB 2.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.6/10.5 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.9/10.5 MB 2.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.1/10.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.4/10.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.6/10.5 MB 2.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.9/10.5 MB 3.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.9/10.5 MB 2.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.2/10.5 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.4/10.5 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.7/10.5 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.0/10.5 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.4/10.5 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.6/10.5 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.1/10.5 MB 3.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.3/10.5 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.7/10.5 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.8/10.5 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.2/10.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.4/10.5 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.5/10.5 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.5/10.5 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading trio-0.25.0-py3-none-any.whl (467 kB)\n",
      "   ---------------------------------------- 0.0/467.2 kB ? eta -:--:--\n",
      "   -------------- ------------------------ 174.1/467.2 kB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  460.8/467.2 kB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 467.2/467.2 kB 7.4 MB/s eta 0:00:00\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "   ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 60.8/60.8 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.3/58.3 kB ? eta 0:00:00\n",
      "Installing collected packages: typing_extensions, sniffio, h11, attrs, wsproto, outcome, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.2.0\n",
      "    Uninstalling sniffio-1.2.0:\n",
      "      Successfully uninstalled sniffio-1.2.0\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 22.1.0\n",
      "    Uninstalling attrs-22.1.0:\n",
      "      Successfully uninstalled attrs-22.1.0\n",
      "Successfully installed attrs-23.2.0 h11-0.14.0 outcome-1.3.0.post0 selenium-4.19.0 sniffio-1.3.1 trio-0.25.0 trio-websocket-0.11.1 typing_extensions-4.11.0 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selenium version: 4.19.0\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "\n",
    "print(\"Selenium version:\", selenium.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WebDriver' object has no attribute 'find_elements_by_xpath'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Find all links on the page that end with \".pdf\"\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m pdf_links \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements_by_xpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//a[contains(@href, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Download each PDF file to the specified directory\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m pdf_links:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'find_elements_by_xpath'"
     ]
    }
   ],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "import os\n",
    "\n",
    "# Set the path to the Chrome WebDriver executable\n",
    "# webdriver_path = '/path/to/chromedriver'  # Update this with the path to your chromedriver executable\n",
    "download_dir = r'C:\\Users\\VenkataGurnadhamRavu\\Desktop\\python'\n",
    "\n",
    "# Specify Chrome options to set the download directory\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {'download.default_directory': download_dir}\n",
    "chrome_options.add_experimental_option('prefs', prefs)\n",
    "\n",
    "# Initialize Chrome WebDriver with the specified options\n",
    "# driver = webdriver.Chrome(webdriver_path, options=chrome_options)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the webpage containing the PDF links\n",
    "url = \"https://getsamplefiles.com/sample-document-files/pdf\"  # Update this with the URL of the webpage\n",
    "driver.get(url)\n",
    "\n",
    "# Find all links on the page that end with \".pdf\"\n",
    "pdf_links = driver.find_elements_by_xpath(\"//a[contains(@href, '.pdf')]\")\n",
    "\n",
    "# Download each PDF file to the specified directory\n",
    "for link in pdf_links:\n",
    "    pdf_url = link.get_attribute(\"href\")\n",
    "    pdf_name = pdf_url.split(\"/\")[-1]  # Extract filename from URL\n",
    "    pdf_path = os.path.join(download_dir, pdf_name)\n",
    "\n",
    "    # Download PDF file\n",
    "    link.click()\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WebDriver' object has no attribute 'find_elements_by_tag_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Find all links on the page\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m all_links \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements_by_tag_name(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Filter links that end with \".pdf\"\u001b[39;00m\n\u001b[0;32m     25\u001b[0m pdf_links \u001b[38;5;241m=\u001b[39m [link\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m all_links \u001b[38;5;28;01mif\u001b[39;00m link\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'find_elements_by_tag_name'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import os\n",
    "\n",
    "# Set the path to the Chrome WebDriver executable\n",
    "# webdriver_path = '/path/to/chromedriver'  # Update this with the path to your chromedriver executable\n",
    "download_dir = r'C:\\Users\\VenkataGurnadhamRavu\\Desktop\\python'\n",
    "\n",
    "# Specify Chrome options to set the download directory\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {'download.default_directory': download_dir}\n",
    "chrome_options.add_experimental_option('prefs', prefs)\n",
    "\n",
    "# Initialize Chrome WebDriver with the specified options\n",
    "# driver = webdriver.Chrome(webdriver_path, options=chrome_options)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the webpage containing the PDF links\n",
    "url = \"https://getsamplefiles.com/sample-document-files/pdf\"  # Update this with the URL of the webpage\n",
    "driver.get(url)\n",
    "\n",
    "# Find all links on the page\n",
    "all_links = driver.find_elements_by_tag_name(\"a\")\n",
    "\n",
    "# Filter links that end with \".pdf\"\n",
    "pdf_links = [link.get_attribute(\"href\") for link in all_links if link.get_attribute(\"href\").endswith(\".pdf\")]\n",
    "\n",
    "# Download each PDF file to the specified directory\n",
    "for pdf_url in pdf_links:\n",
    "    pdf_name = pdf_url.split(\"/\")[-1]  # Extract filename from URL\n",
    "    pdf_path = os.path.join(download_dir, pdf_name)\n",
    "\n",
    "    # Download PDF file\n",
    "    driver.get(pdf_url)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WebDriver' object has no attribute 'find_elements_by_css_selector'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 26\u001b[0m\n\u001b[0;32m     18\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Find all links on the page\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# all_links = driver.find_elements_by_tag_name(\"a\")\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# # Filter links that end with \".pdf\"\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# pdf_links = [link.get_attribute(\"href\") for link in all_links if link.get_attribute(\"href\").endswith(\".pdf\")]\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# pdf_links = driver.find_element(\"a[href$='.pdf']\")\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m pdf_links \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements_by_css_selector(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma[href$=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Download each PDF file to the specified directory\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pdf_link \u001b[38;5;129;01min\u001b[39;00m pdf_links:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Get the download link\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'find_elements_by_css_selector'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import os\n",
    "\n",
    "# Set the path to the Chrome WebDriver executable\n",
    "# webdriver_path = r'C:\\Users\\VenkataGurnadhamRavu\\Desktop\\python'  # Update this with the path to your chromedriver executable\n",
    "download_dir = r'C:\\Users\\VenkataGurnadhamRavu\\Desktop\\python'\n",
    "\n",
    "# Specify Chrome options to set the download directory\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {'download.default_directory': download_dir}\n",
    "chrome_options.add_experimental_option('prefs', prefs)\n",
    "\n",
    "# Initialize Chrome WebDriver with the specified options\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Navigate to the webpage containing the PDF links\n",
    "url = \"https://app.financial-cents.com/login%22\" \n",
    "driver.get(url)\n",
    "\n",
    "# Find all links on the page\n",
    "# all_links = driver.find_elements_by_tag_name(\"a\")\n",
    "\n",
    "# # Filter links that end with \".pdf\"\n",
    "# pdf_links = [link.get_attribute(\"href\") for link in all_links if link.get_attribute(\"href\").endswith(\".pdf\")]\n",
    "# pdf_links = driver.find_element(\"a[href$='.pdf']\")\n",
    "pdf_links = driver.find_elements_by_css_selector(\"a[href$='.pdf']\")\n",
    "\n",
    "# Download each PDF file to the specified directory\n",
    "for pdf_link in pdf_links:\n",
    "    # Get the download link\n",
    "    pdf_url = pdf_link.get_attribute(\"href\")\n",
    "\n",
    "    # Extract filename from the URL\n",
    "    pdf_name = pdf_url.split(\"/\")[-1]\n",
    "\n",
    "    # Download PDF file to the specified directory\n",
    "    pdf_path = os.path.join(download_dir, pdf_name)\n",
    "\n",
    "    # Download PDF file\n",
    "    driver.get(pdf_url)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded PDF: sample-1.pdf\n",
      "Downloaded PDF: sample-2.pdf\n",
      "Downloaded PDF: sample-3.pdf\n",
      "Downloaded PDF: sample-4.pdf\n",
      "Downloaded PDF: sample-5.pdf\n",
      "Download complete!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# Target URL containing PDF links\n",
    "url = \"https://getsamplefiles.com/sample-document-files/pdf\"\n",
    "\n",
    "# Download directory for PDFs\n",
    "download_dir = \"C:/Users/VenkataGurnadhamRavu/Desktop/python\"  # Update this path\n",
    "\n",
    "# Fetch the HTML content of the webpage\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find all anchor tags with href ending in '.pdf'\n",
    "pdf_links = [a[\"href\"] for a in soup.find_all(\"a\", href=lambda href: href and href.endswith(\".pdf\"))]\n",
    "\n",
    "# Download each PDF file\n",
    "for pdf_url in pdf_links:\n",
    "    # Extract filename from the URL\n",
    "    pdf_name = pdf_url.split(\"/\")[-1]\n",
    "\n",
    "    # Construct the full download path\n",
    "    pdf_path = os.path.join(download_dir, pdf_name)\n",
    "\n",
    "    # Download the PDF content\n",
    "    pdf_response = requests.get(pdf_url, stream=True)\n",
    "\n",
    "    # Check for successful download status code\n",
    "    if pdf_response.status_code == 200:\n",
    "        # Write the PDF content to the file\n",
    "        with open(pdf_path, \"wb\") as f:\n",
    "            for chunk in pdf_response.iter_content(1024):\n",
    "                f.write(chunk)\n",
    "        print(f\"Downloaded PDF: {pdf_name}\")\n",
    "    else:\n",
    "        print(f\"Failed to download: {pdf_url}\")\n",
    "\n",
    "print(\"Download complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# Target URL containing PDF links\n",
    "url = \"https://app.financial-cents.com/login%22\"\n",
    "\n",
    "# Download directory for PDFs\n",
    "download_dir = \"C:/Users/VenkataGurnadhamRavu/Desktop/python\"  # Update this path\n",
    "\n",
    "# Fetch the HTML content of the webpage\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find all anchor tags with href ending in '.pdf'\n",
    "pdf_links = [a[\"href\"] for a in soup.find_all(\"a\", href=lambda href: href and href.endswith(\".pdf\"))]\n",
    "\n",
    "# Download each PDF file\n",
    "for pdf_url in pdf_links:\n",
    "    # Extract filename from the URL\n",
    "    pdf_name = pdf_url.split(\"/\")[-1]\n",
    "\n",
    "    # Construct the full download path\n",
    "    pdf_path = os.path.join(download_dir, pdf_name)\n",
    "\n",
    "    # Download the PDF content\n",
    "    pdf_response = requests.get(pdf_url, stream=True)\n",
    "\n",
    "    # Check for successful download status code\n",
    "    if pdf_response.status_code == 200:\n",
    "        # Write the PDF content to the file\n",
    "        with open(pdf_path, \"wb\") as f:\n",
    "            for chunk in pdf_response.iter_content(1024):\n",
    "                f.write(chunk)\n",
    "        print(f\"Downloaded PDF: {pdf_name}\")\n",
    "    else:\n",
    "        print(f\"Failed to download: {pdf_url}\")\n",
    "\n",
    "print(\"Download complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import os\n",
    "download_dir = r'C:\\Users\\VenkataGurnadhamRavu\\Desktop\\python'\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {'download.default_directory': download_dir}\n",
    "chrome_options.add_experimental_option('prefs', prefs)\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "url = \"https://go.ignitionapp.com/discover\" \n",
    "driver.get(url)\n",
    "# pdf_links = driver.find_elements_by_css_selector(\"a[href$='.pdf']\")\n",
    "# Find all anchor tags with href ending with \".pdf\" using XPath\n",
    "pdf_links = driver.find_elements(By.XPATH, \"//a[contains(@href, '.pdf')]\")\n",
    "print(pdf_links)\n",
    "for pdf_link in pdf_links:\n",
    "   \n",
    "    pdf_url = pdf_link.get_attribute(\"href\")\n",
    "    pdf_name = pdf_url.split(\"/\")[-1]\n",
    "    pdf_path = os.path.join(download_dir, pdf_name)\n",
    "    driver.get(pdf_url)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import os\n",
    "download_dir = r'C:\\Users\\VenkataGurnadhamRavu\\Desktop\\python'\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {'download.default_directory': download_dir}\n",
    "chrome_options.add_experimental_option('prefs', prefs)\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "url = \"https://app.financial-cents.com/login%22\" \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded PDF: sample-1.pdf\n",
      "Downloaded PDF: sample-2.pdf\n",
      "Downloaded PDF: sample-3.pdf\n",
      "Downloaded PDF: sample-4.pdf\n",
      "Downloaded PDF: sample-5.pdf\n",
      "Download complete!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "url = \"https://getsamplefiles.com/sample-document-files/pdf\"\n",
    "download_dir = \"C:/Users/VenkataGurnadhamRavu/Desktop/python\"  # Update this path\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "pdf_links = [a[\"href\"] for a in soup.find_all(\"a\", href=lambda href: href and href.endswith(\".pdf\"))]\n",
    "for pdf_url in pdf_links:\n",
    "    pdf_name = pdf_url.split(\"/\")[-1]\n",
    "    pdf_path = os.path.join(download_dir, pdf_name)\n",
    "    pdf_response = requests.get(pdf_url, stream=True)\n",
    "    if pdf_response.status_code == 200:\n",
    "        with open(pdf_path, \"wb\") as f:\n",
    "            for chunk in pdf_response.iter_content(1024):\n",
    "                f.write(chunk)\n",
    "        print(f\"Downloaded PDF: {pdf_name}\")\n",
    "    else:\n",
    "        print(f\"Failed to download: {pdf_url}\")\n",
    "\n",
    "print(\"Download complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Download complete!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# Target URL containing PDF links\n",
    "url = \"https://app.financial-cents.com/login\"\n",
    "\n",
    "# Download directory for PDFs\n",
    "download_dir = \"C:/Users/VenkataGurnadhamRavu/Desktop/python\"  # Update this path\n",
    "\n",
    "# Fetch the HTML content of the webpage\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find all anchor tags with href ending in '.pdf'\n",
    "pdf_links = [a[\"href\"] for a in soup.find_all(\"a\", href=lambda href: href and href.endswith(\".pdf\"))]\n",
    "print(pdf_links)\n",
    "# Download each PDF file\n",
    "for pdf_url in pdf_links:\n",
    "    # Extract filename from the URL\n",
    "    pdf_name = pdf_url.split(\"/\")[-1]\n",
    "\n",
    "    # Construct the full download path\n",
    "    pdf_path = os.path.join(download_dir, pdf_name)\n",
    "\n",
    "    # Download the PDF content\n",
    "    pdf_response = requests.get(pdf_url, stream=True)\n",
    "\n",
    "    # Check for successful download status code\n",
    "    if pdf_response.status_code == 200:\n",
    "        # Write the PDF content to the file\n",
    "        with open(pdf_path, \"wb\") as f:\n",
    "            for chunk in pdf_response.iter_content(1024):\n",
    "                f.write(chunk)\n",
    "        print(f\"Downloaded PDF: {pdf_name}\")\n",
    "    else:\n",
    "        print(f\"Failed to download: {pdf_url}\")\n",
    "\n",
    "print(\"Download complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAPTCHA pop-up not found or failed to load within the timeout.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'WebDriver' object has no attribute 'find_element_by_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAPTCHA pop-up not found or failed to load within the timeout.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# If CAPTCHA pop-up found, try clicking it\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m captcha_popup \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element_by_id(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaptcha-popup\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m captcha_popup\u001b[38;5;241m.\u001b[39mis_displayed():\n\u001b[0;32m     32\u001b[0m     captcha_popup\u001b[38;5;241m.\u001b[39mclick()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'find_element_by_id'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import os\n",
    "import time\n",
    "\n",
    "download_dir = r'C:\\Users\\VenkataGurnadhamRavu\\Desktop\\python'\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {'download.default_directory': download_dir}\n",
    "chrome_options.add_experimental_option('prefs', prefs)\n",
    "\n",
    "# Initialize Chrome WebDriver with the specified options\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Navigate to the webpage\n",
    "url = \"https://app.financial-cents.com/login\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the CAPTCHA pop-up to appear\n",
    "# Assuming the CAPTCHA pop-up appears after 10 seconds (adjust as needed)\n",
    "try:\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, \"captcha-popup\")))\n",
    "except:\n",
    "    print(\"CAPTCHA pop-up not found or failed to load within the timeout.\")\n",
    "\n",
    "# If CAPTCHA pop-up found, try clicking it\n",
    "captcha_popup = driver.find_element_by_id(\"captcha-popup\")\n",
    "if captcha_popup.is_displayed():\n",
    "    captcha_popup.click()\n",
    "    print(\"Clicked CAPTCHA pop-up.\")\n",
    "\n",
    "# Wait for some time for the CAPTCHA verification to complete (adjust as needed)\n",
    "time.sleep(10)\n",
    "\n",
    "# Find all anchor tags with href ending with \".pdf\"\n",
    "pdf_links = driver.find_elements_by_css_selector(\"a[href$='.pdf']\")\n",
    "\n",
    "# Download each PDF file to the specified directory\n",
    "for pdf_link in pdf_links:\n",
    "    # Get the download link\n",
    "    pdf_url = pdf_link.get_attribute(\"href\")\n",
    "\n",
    "    # Extract filename from the URL\n",
    "    pdf_name = pdf_url.split(\"/\")[-1]\n",
    "\n",
    "    # Download PDF file to the specified directory\n",
    "    pdf_path = os.path.join(download_dir, pdf_name)\n",
    "\n",
    "    # Download PDF file\n",
    "    driver.get(pdf_url)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import os\n",
    "\n",
    "# Set the path to the Chrome WebDriver executable\n",
    "# webdriver_path = '/path/to/chromedriver'  # Update this with the path to your chromedriver executable\n",
    "download_dir = r'C:\\Users\\VenkataGurnadhamRavu\\Desktop\\python'\n",
    "\n",
    "# Specify Chrome options to set the download directory\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {'download.default_directory': download_dir}\n",
    "chrome_options.add_experimental_option('prefs', prefs)\n",
    "\n",
    "# Initialize Chrome WebDriver with the specified options\n",
    "driver = webdriver.Chrome( options=chrome_options)\n",
    "\n",
    "# Navigate to the webpage containing the PDF links\n",
    "url = \"https://app.financial-cents.com/login\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for some time for the CAPTCHA verification to complete (adjust as needed)\n",
    "time.sleep(10)\n",
    "\n",
    "# Find all anchor tags with href ending with \".pdf\"\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import os\n",
    "\n",
    "# Set the path to the Chrome WebDriver executable\n",
    "webdriver_path = '/path/to/chromedriver'  # Update this with the path to your chromedriver executable\n",
    "download_dir = r'C:\\Users\\VenkataGurnadhamRavu\\Desktop\\python'\n",
    "\n",
    "# Specify Chrome options to set the download directory\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {'download.default_directory': download_dir}\n",
    "chrome_options.add_experimental_option('prefs', prefs)\n",
    "\n",
    "# Initialize Chrome WebDriver with the specified options\n",
    "driver = webdriver.Chrome(executable_path=webdriver_path, options=chrome_options)\n",
    "\n",
    "# Navigate to the webpage containing the PDF links\n",
    "url = \"https://app.financial-cents.com/login\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for some time for the CAPTCHA verification to complete (adjust as needed)\n",
    "time.sleep(10)\n",
    "\n",
    "# Find all anchor tags with href ending with \".pdf\"\n",
    "pdf_links = driver.find_elements(By.CSS_SELECTOR, \"a[href$='.pdf']\")\n",
    "\n",
    "# Download each PDF file to the specified directory\n",
    "for pdf_link in pdf_links:\n",
    "    # Get the download link\n",
    "    pdf_url = pdf_link.get_attribute(\"href\")\n",
    "\n",
    "    # Extract filename from the URL\n",
    "    pdf_name = pdf_url.split(\"/\")[-1]\n",
    "\n",
    "    # Download PDF file to the specified directory\n",
    "    pdf_path = os.path.join(download_dir, pdf_name)\n",
    "\n",
    "    # Download PDF file\n",
    "    driver.get(pdf_url)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "print(pdf_links)\n",
    "# Download each PDF file to the specified directory\n",
    "for pdf_link in pdf_links:\n",
    "    # Get the download link\n",
    "    pdf_url = pdf_link.get_attribute(\"href\")\n",
    "\n",
    "    # Extract filename from the URL\n",
    "    pdf_name = pdf_url.split(\"/\")[-1]\n",
    "\n",
    "    # Download PDF file to the specified directory\n",
    "    pdf_path = os.path.join(download_dir, pdf_name)\n",
    "\n",
    "    # Download PDF file\n",
    "    driver.get(pdf_url)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAPTCHA pop-up not found or failed to load within the timeout.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import os\n",
    "\n",
    "# Set the path to the Chrome WebDriver executable\n",
    "# webdriver_path = '/path/to/chromedriver'  # Update this with the path to your chromedriver executable\n",
    "download_dir = r'C:\\Users\\VenkataGurnadhamRavu\\Desktop\\python'\n",
    "\n",
    "# Specify Chrome options to set the download directory\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {'download.default_directory': download_dir}\n",
    "chrome_options.add_experimental_option('prefs', prefs)\n",
    "\n",
    "# Initialize Chrome WebDriver with the specified options\n",
    "driver = webdriver.Chrome( options=chrome_options)\n",
    "\n",
    "# Navigate to the webpage containing the PDF links\n",
    "url = \"https://app.financial-cents.com/login\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the CAPTCHA pop-up to appear\n",
    "try:\n",
    "    captcha_popup = WebDriverWait(driver, 40).until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"div[class^='recaptcha']\")))\n",
    "    # If CAPTCHA pop-up found, try clicking it\n",
    "    if captcha_popup.is_displayed():\n",
    "        captcha_popup.click()\n",
    "        print(\"Clicked CAPTCHA pop-up.\")\n",
    "except:\n",
    "    print(\"CAPTCHA pop-up not found or failed to load within the timeout.\")\n",
    "\n",
    "# Wait for some time for the CAPTCHA verification to complete (adjust as needed)\n",
    "time.sleep(10)\n",
    "\n",
    "# Find all anchor tags with href ending with \".pdf\"\n",
    "pdf_links = driver.find_elements(By.CSS_SELECTOR, \"a[href$='.pdf']\")\n",
    "\n",
    "# Download each PDF file to the specified directory\n",
    "for pdf_link in pdf_links:\n",
    "    # Get the download link\n",
    "    pdf_url = pdf_link.get_attribute(\"href\")\n",
    "\n",
    "    # Extract filename from the URL\n",
    "    pdf_name = pdf_url.split(\"/\")[-1]\n",
    "\n",
    "    # Download PDF file to the specified directory\n",
    "    pdf_path = os.path.join(download_dir, pdf_name)\n",
    "\n",
    "    # Download PDF file\n",
    "    driver.get(pdf_url)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
